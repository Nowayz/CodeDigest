Directory Structure
==================
├── .git/
│   ├── COMMIT_EDITMSG
│   ├── config
│   ├── description
│   ├── FETCH_HEAD
│   ├── HEAD
│   ├── hooks/
│   │   ├── applypatch-msg.sample
│   │   ├── commit-msg.sample
│   │   ├── fsmonitor-watchman.sample
│   │   ├── post-update.sample
│   │   ├── pre-applypatch.sample
│   │   ├── pre-commit.sample
│   │   ├── pre-merge-commit.sample
│   │   ├── pre-push.sample
│   │   ├── pre-rebase.sample
│   │   ├── pre-receive.sample
│   │   ├── prepare-commit-msg.sample
│   │   ├── push-to-checkout.sample
│   │   └── update.sample
│   ├── index
│   ├── info/
│   │   └── exclude
│   ├── logs/
│   │   ├── HEAD
│   │   └── refs/
│   │       ├── heads/
│   │       │   └── main
│   │       └── remotes/
│   │           └── origin/
│   │               └── HEAD
│   ├── objects/
│   │   ├── 8b/
│   │   │   └── ee1cd020156553effdda09cc3ba67151f617b4
│   │   ├── 96/
│   │   │   └── f884308b7374a24542a7271dbff7ebf01f3a4d
│   │   ├── ae/
│   │   │   └── 77961bc9817a0203233c3d9cfb3c4e5b3e0b78
│   │   ├── c7/
│   │   │   └── cf2e822cb857ca2f614ecccac57e9d4b090d96
│   │   ├── ca/
│   │   │   └── 54c260b208c76b6267ae2f716e61dfa128699d
│   │   ├── ea/
│   │   │   └── cbbe2092f7910a26b9cbdee8bd2d4bc97290b1
│   │   ├── info/
│   │   └── pack/
│   │       ├── pack-bc190372c2b8af83ffe68c57d9de7839884beb97.idx
│   │       └── pack-bc190372c2b8af83ffe68c57d9de7839884beb97.pack
│   ├── packed-refs
│   └── refs/
│       ├── heads/
│       │   └── main
│       ├── remotes/
│       │   └── origin/
│       │       └── HEAD
│       └── tags/
├── codedigest.mjs
├── LICENSE
└── README.md


File Contents
=============
================================================
File: .git\COMMIT_EDITMSG
================================================
Fix: max size option not respected

================================================
File: .git\config
================================================
[core]
	repositoryformatversion = 0
	filemode = false
	bare = false
	logallrefupdates = true
	ignorecase = true
[remote "origin"]
	url = https://github.com/Nowayz/CodeDigest.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
	remote = origin
	merge = refs/heads/main
	vscode-merge-base = origin/main

================================================
File: .git\description
================================================
Unnamed repository; edit this file 'description' to name the repository.

================================================
File: .git\FETCH_HEAD
================================================
99cddfc16ad98e6473c1d7e6452a8089b4526aed		branch 'main' of https://github.com/Nowayz/CodeDigest
f5cdf580ab3e43e0276650dad686887188a7180e	not-for-merge	branch 'resources' of https://github.com/Nowayz/CodeDigest

================================================
File: .git\HEAD
================================================
ref: refs/heads/main

================================================
File: .git\hooks\applypatch-msg.sample
================================================
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:

================================================
File: .git\hooks\commit-msg.sample
================================================
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}

================================================
File: .git\hooks\fsmonitor-watchman.sample
================================================
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	my $last_update_line = "";
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
		$last_update_line = qq[\n"since": $last_update_token,];
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {$last_update_line
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}

================================================
File: .git\hooks\post-update.sample
================================================
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info

================================================
File: .git\hooks\pre-applypatch.sample
================================================
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:

================================================
File: .git\hooks\pre-commit.sample
================================================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --

================================================
File: .git\hooks\pre-merge-commit.sample
================================================
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:

================================================
File: .git\hooks\pre-push.sample
================================================
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0

================================================
File: .git\hooks\pre-rebase.sample
================================================
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END

================================================
File: .git\hooks\pre-receive.sample
================================================
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi

================================================
File: .git\hooks\prepare-commit-msg.sample
================================================
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi

================================================
File: .git\hooks\push-to-checkout.sample
================================================
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi

================================================
File: .git\hooks\update.sample
================================================
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0

================================================
File: .git\info\exclude
================================================
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~

================================================
File: .git\logs\HEAD
================================================
0000000000000000000000000000000000000000 99cddfc16ad98e6473c1d7e6452a8089b4526aed Phillip McNallen <phil@3rdera.com> 1737574534 -0600	clone: from https://github.com/Nowayz/CodeDigest.git
99cddfc16ad98e6473c1d7e6452a8089b4526aed ae77961bc9817a0203233c3d9cfb3c4e5b3e0b78 Phillip McNallen <phil@3rdera.com> 1737575457 -0600	commit: Fixed shouldIgnore, added --skip-default-ignore
ae77961bc9817a0203233c3d9cfb3c4e5b3e0b78 ca54c260b208c76b6267ae2f716e61dfa128699d Phillip McNallen <phil@3rdera.com> 1737575569 -0600	commit: Fix: max size option not respected

================================================
File: .git\logs\refs\heads\main
================================================
0000000000000000000000000000000000000000 99cddfc16ad98e6473c1d7e6452a8089b4526aed Phillip McNallen <phil@3rdera.com> 1737574534 -0600	clone: from https://github.com/Nowayz/CodeDigest.git
99cddfc16ad98e6473c1d7e6452a8089b4526aed ae77961bc9817a0203233c3d9cfb3c4e5b3e0b78 Phillip McNallen <phil@3rdera.com> 1737575457 -0600	commit: Fixed shouldIgnore, added --skip-default-ignore
ae77961bc9817a0203233c3d9cfb3c4e5b3e0b78 ca54c260b208c76b6267ae2f716e61dfa128699d Phillip McNallen <phil@3rdera.com> 1737575569 -0600	commit: Fix: max size option not respected

================================================
File: .git\logs\refs\remotes\origin\HEAD
================================================
0000000000000000000000000000000000000000 99cddfc16ad98e6473c1d7e6452a8089b4526aed Phillip McNallen <phil@3rdera.com> 1737574534 -0600	clone: from https://github.com/Nowayz/CodeDigest.git

================================================
File: .git\objects\ae\77961bc9817a0203233c3d9cfb3c4e5b3e0b78
================================================
x��KJ1DgY����G��-�ν��Kw��4�|�Kpv8EQ�ھ��gF'�����a��X�5��+\s��f����N��1&Ĝ�����:)��A��Np@��[��k+����O���|N�;R��������XυtR�i��A�k���C��[�*���#�鄸��)�2\u���_�PT�
================================================
File: .git\objects\ca\54c260b208c76b6267ae2f716e61dfa128699d
================================================
x��Aj�0@Ѯu��@�Ɠ��PJW٥�
�hL�%BO_�!���m+&Ʒ�UaN�(�N�1�.K��J�yd\�t2-v�D�>8Lf��`4	� K"9)'R��l�c�j��[Y���*?q]u��v�o�Y{���}z��]�w�5G=���ͥ<ϰ�'�˟Bm���:�뽩���)Pq
================================================
File: .git\packed-refs
================================================
# pack-refs with: peeled fully-peeled sorted 
99cddfc16ad98e6473c1d7e6452a8089b4526aed refs/remotes/origin/main
f5cdf580ab3e43e0276650dad686887188a7180e refs/remotes/origin/resources

================================================
File: .git\refs\heads\main
================================================
ca54c260b208c76b6267ae2f716e61dfa128699d

================================================
File: .git\refs\remotes\origin\HEAD
================================================
ref: refs/remotes/origin/main

================================================
File: codedigest.mjs
================================================
#!/usr/bin/env node

/**
 * codedigest.mjs - A Node.js script to generate a digest of a directory's structure and file contents.
 *
 * @module codedigest.mjs
 */

import { readFileSync, writeFileSync, existsSync, mkdirSync, lstatSync, readdirSync, readlinkSync, openSync, readSync, closeSync } from 'node:fs';
import { join, extname, dirname, relative, resolve, sep, normalize } from 'node:path';

const MAX_FILE_SIZE        = 10 * 1024 * 1024;  // 10 MB
const MAX_DIRECTORY_DEPTH  = 20;
const MAX_TOTAL_SIZE_BYTES = 500 * 1024 * 1024; // 500 MB
const CHUNK_SIZE           = 1024 * 1024;       // 1 MB

/**
 * Default patterns to ignore.
 *
 * @type {Set<string>}
 */
const DEFAULT_IGNORE_PATTERNS = new Set([
  '*.pyc',           '*.pyo',           '*.pyd',           '__pycache__',     '.pytest_cache',
  '.coverage',       '.tox',            '.nox',            '.mypy_cache',     '.ruff_cache',
  '.hypothesis',     'poetry.lock',     'Pipfile.lock',    'node_modules',    'bower_components',
  'package-lock.json','yarn.lock',      '.npm',            '.yarn',           '.pnpm-store',
  '*.class',         '*.jar',           '*.war',           '*.ear',           '*.nar',
  '.gradle/',        'build/',          '.settings/',      '.classpath',      'gradle-app.setting',
  '*.gradle',        '.project',        '*.o',             '*.obj',           '*.dll',
  '*.dylib',         '*.exe',           '*.lib',           '*.out',           '*.a',
  '*.pdb',           '.build/',         '*.xcodeproj/',    '*.xcworkspace/',  '*.pbxuser',
  '*.mode1v3',       '*.mode2v3',       '*.perspectivev3', '*.xcuserstate',   'xcuserdata/',
  '.swiftpm/',       '*.gem',           '.bundle/',        'vendor/bundle',   'Gemfile.lock',
  '.ruby-version',   '.ruby-gemset',    '.rvmrc',          'Cargo.lock',      '**/*.rs.bk',
  'target/',         'pkg/',            'obj/',            '*.suo',           '*.user',
  '*.userosscache',  '*.sln.docstates', 'packages/',       '*.nupkg',         'bin/',
  '.git',            '.svn',            '.hg',             '.gitignore',      '.gitattributes',
  '.gitmodules',     '*.svg',           '*.png',           '*.jpg',           '*.jpeg',
  '*.gif',           '*.ico',           '*.pdf',           '*.mov',           '*.mp4',
  '*.mp3',           '*.wav',           'venv',            '.venv',           'env',
  '.env',            'virtualenv',      '.idea',           '.vscode',         '.vs',
  '*.swo',           '*.swn',           '.settings',       '*.sublime-*',     '*.log',
  '*.bak',           '*.swp',           '*.tmp',           '*.temp',          '.cache',
  '.sass-cache',     '.eslintcache',    '.DS_Store',       'Thumbs.db',       'desktop.ini',
  'build',           'dist',            'target',          'out',             '*.egg-info',
  '*.egg',           '*.whl',           '*.so',            'site-packages',   '.docusaurus',
  '.next',           '.nuxt',           '*.min.js',        '*.min.css',       '*.map',
  '.terraform',      '*.tfstate*',      'vendor/',
]);

/**
 * ANSI escape codes for formatting.
 */
const FORMAT = {
  bold:   (text) => `\x1b[1m${text}\x1b[0m`,
  red:    (text) => `\x1b[31m${text}\x1b[0m`,
  green:  (text) => `\x1b[32m${text}\x1b[0m`,
  yellow: (text) => `\x1b[33m${text}\x1b[0m`,
  white:  (text) => `\x1b[37m${text}\x1b[0m`,
  gray:   (text) => `\x1b[90m${text}\x1b[0m`,
  invert: (text) => `\x1b[7m${text}\x1b[27m`,
};

/**
 * @typedef {Object} FileInfo
 * @property {string} path - The relative path of the file.
 * @property {string} content - The content of the file.
 * @property {number} size - The size of the file in bytes.
 */

/**
 * @typedef {Object} ProcessingStats
 * @property {number} totalSize - The total size of processed files in bytes.
 * @property {number} fileCount - The number of files processed.
 * @property {Set<string>} seenPaths - A set of resolved paths to detect circular references.
 * @property {Set<string>} seenSymlinks - A set of "entry:target" symlink pairs to detect circular symlinks.
 * @property {Array<{timestamp: string, message: string, stack?: string}>} errors - An array of error objects.
 * @property {number} skippedFiles - The number of files skipped due to exceeding maxFileSize.
 * @property {number} excludedFiles - The number of files excluded by pattern.
 * @property {number} nonTextFiles - The number of files excluded because they are not text files.
 * @property {boolean} sizeLimitReached - Indicates if the total size limit was reached.
 * @property {number} startTime - Timestamp of the start of processing.
 * @property {Set<string>} matchedIgnorePatterns - Set of ignore patterns that matched at least one file/directory.
 */

/**
 * @typedef {Object} ProcessingOptions
 * @property {string[]} ignorePatterns - Patterns of files and directories to ignore.
 * @property {string[]} includePatterns - Patterns of files and directories to include.
 * @property {number} maxFileSize - Maximum file size to process.
 * @property {number} maxTotalSize - Maximum total size of files to process.
 * @property {number} maxDepth - Maximum directory traversal depth.
 * @property {string} rootPath - The absolute path of the root directory being processed.
 * @property {boolean} quiet - Whether to suppress Added and Skipped messages.
 * @property {boolean} ultraQuiet - Whether to suppress all non-error output.
 * @property {boolean} omitExcluded - Whether to omit excluded files from the directory tree.
 */

/**
 * Creates a new ProcessingStats object.
 *
 * @returns {ProcessingStats} A new ProcessingStats object.
 */
const createStats = () => ({
  totalSize:             0,
  fileCount:             0,
  seenPaths:             new Set(),
  seenSymlinks:          new Set(),
  errors:                [],
  skippedFiles:          0,
  excludedFiles:         0,
  nonTextFiles:          0,
  sizeLimitReached:      false,
  startTime:             Date.now(),
  matchedIgnorePatterns: new Set(),

  /**
   * Adds an error to the errors array.
   *
   * @param {Error} error - The error object to add.
   */
  addError(error) {
    this.errors.push({
      timestamp: new Date().toISOString(),
      message:   error.message,
      stack:     error.stack,
    });
  },
});

/**
 * Matches a file path against a glob pattern.
 *
 * @param {string} path - The file path to match.
 * @param {string} pattern - The glob pattern to match against.
 * @param {Object} [opts={}] - Options for matching.
 * @param {boolean} [opts.nocase=false] - Perform case-insensitive matching.
 * @param {boolean} [opts.dot=false] - Match dotfiles.
 * @returns {boolean} True if the path matches the pattern, false otherwise.
 */
function miniMatch(path, pattern, opts = {}) {
  try {
    if (!pattern || typeof pattern !== 'string') {
      console.warn(`Invalid pattern: ${pattern}`);
      return false;
    }

    const options         = { nocase: false, dot: false, ...opts };
    const { nocase, dot } = options;

    /**
     * Escapes special regular expression characters in a string.
     *
     * @param {string} s - The string to escape.
     * @returns {string} The escaped string.
     */
    const escapeRegExp = (s) => s.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');

    let pat = pattern;
    let neg = false;
    if (pat.startsWith('!')) {
      neg = true;
      pat = pat.slice(1);
    }

    const parts     = pat.split(sep);
    const pathParts = path.split(sep);

    /**
     * Matches a single path part against a pattern part.
     *
     * @param {string} pathPart - The path part.
     * @param {string} patPart - The pattern part.
     * @returns {boolean} True if the parts match, false otherwise.
     */
    const matchPart = (pathPart, patPart) => {
      if (patPart === '**') return true;
      const regexStr = patPart.split('*').map(escapeRegExp).join('.*');
      const regex    = new RegExp(`^${regexStr}$`, nocase ? 'i' : '');
      return regex.test(pathPart);
    };

    if (!dot && path.split('/').some((part) => part.startsWith('.'))) {
      if (!pat.split('/').some((part) => part.startsWith('.'))) {
        return false;
      }
    }

    /**
     * Recursively matches path parts against pattern parts.
     *
     * @param {string[]} pathParts - The path parts.
     * @param {string[]} patParts - The pattern parts.
     * @returns {boolean} True if the path matches the pattern, false otherwise.
     */
    const match = (pathParts, patParts) => {
      if (patParts.length === 0) return pathParts.length === 0;
      if (patParts[0] === '**') {
        if (patParts.length === 1) return true;
        for (let i = 0; i <= pathParts.length; i++) {
          if (match(pathParts.slice(i), patParts.slice(1))) return true;
        }
        return false;
      }
      if (pathParts.length === 0 || !matchPart(pathParts[0], patParts[0]))
        return false;
      return match(pathParts.slice(1), patParts.slice(1));
    };

    let result = match(pathParts, parts);
    return neg ? !result : result;
  } catch (error) {
    console.error(`Error in pattern matching: ${error.message}`);
    return false;
  }
}

/**
 * Checks if a path should be ignored based on the given ignore patterns,
 * replicating .gitignore-like "last pattern wins" logic, with path normalized
 * to use `/` separators and matchBase for patterns without a slash.
 *
 * @param {string} path - The path to check.
 * @param {string[]} ignorePatterns - The patterns to ignore.
 * @param {Object} minimatchOptions - Options for minimatch.
 * @param {ProcessingStats} [stats] - The processing statistics for tracking matched patterns.
 * @returns {boolean} True if the path should be ignored, false otherwise.
 */
const shouldIgnore = (path, ignorePatterns, minimatchOptions, stats) => {
  // Force forward slashes for consistent matching
  const normalizedPath = normalize(path).split(sep).join('/');

  // Track the final ignore status after evaluating *all* patterns
  let shouldBeIgnored = false;

  for (const pattern of ignorePatterns) {
    const isNegated     = pattern.startsWith('!');
    const actualPattern = isNegated ? pattern.slice(1) : pattern;

    const match = miniMatch(normalizedPath, actualPattern, {
      ...minimatchOptions,
      // For patterns without '/', act like gitignore's "basename" match
      matchBase: !actualPattern.includes('/'),
    });

    if (match) {
      // If we match a non-negated pattern, set ignored to true
      // If we match a negated pattern, set ignored to false
      shouldBeIgnored = !isNegated;

      // Keep track of which pattern matched only if it leads to ignoring
      if (!isNegated && stats) {
        stats.matchedIgnorePatterns.add(pattern);
      }
      // We do NOT return immediately—last pattern wins
    }
  }

  return shouldBeIgnored;
};

/**
 * Reads the content of a file, handling large files in chunks.
 *
 * @param {string} filePath - The path to the file.
 * @param {number} maxFileSize - The maximum file size allowed.
 * @returns {string} The content of the file or an error message.
 */
const readFileContent = (filePath, maxFileSize) => {
  try {
    const stats = lstatSync(filePath);

    if (stats.size > maxFileSize) {
      return `[File too large to display, size: ${formatBytes(stats.size)}]`;
    }

    if (!isTextFile(filePath)) {
      return '[Non-text file]';
    }

    if (stats.size > CHUNK_SIZE) {
      const fd      = openSync(filePath, 'r');
      const buffer  = Buffer.alloc(CHUNK_SIZE);
      let content   = '';
      let bytesRead;

      try {
        while ((bytesRead = readSync(fd, buffer, 0, buffer.length, null)) !== 0) {
          content += buffer.toString('utf8', 0, bytesRead);
        }
      } finally {
        closeSync(fd);
      }
      return content;
    }

    return readFileSync(filePath, 'utf-8');
  } catch (error) {
    return `Error reading file: ${error.message}`;
  }
};

/**
 * Determines if a file is likely a text file based on its extension and content.
 *
 * @param {string} filePath - The path to the file.
 * @returns {boolean} True if the file is likely a text file, false otherwise.
 */
const isTextFile = (filePath) => {
  const textExtensions = new Set([
    '.txt',  '.md',   '.py',  '.js',   '.java', '.c',   '.cpp',  '.h',   '.hpp',
    '.cs',   '.go',   '.rs',  '.swift', '.rb',   '.php',  '.html', '.css',
    '.json', '.xml',  '.yaml','.yml',   '.sh',   '.bat',  '.sql',  '.csv',
    '.tsv',  '.ini',  '.cfg', '.toml',  '.lua',  '.pl',   '.pm',   '.r',
    '.ts',
  ]);

  if (textExtensions.has(extname(filePath).toLowerCase())) {
    return true;
  }

  try {
    const buffer = readFileSync(filePath, { encoding: 'utf8', flag: 'r' });
    return !buffer.includes('\0');
  } catch (error) {
    console.error(`Error checking if file is text: ${error.message}`);
    return false;
  }
};

/**
 * Formats a number of bytes into a human-readable string.
 *
 * @param {number} bytes - The number of bytes.
 * @param {number} [decimals=2] - The number of decimal places to use.
 * @returns {string} The formatted string.
 */
const formatBytes = (bytes, decimals = 2) => {
  if (bytes === 0) return '0 Bytes';
  const k     = 1024;
  const dm    = decimals < 0 ? 0 : decimals;
  const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB', 'PB', 'EB', 'ZB', 'YB'];
  const i     = Math.floor(Math.log(bytes) / Math.log(k));
  return `${parseFloat((bytes / Math.pow(k, i)).toFixed(dm))} ${sizes[i]}`;
};

/**
 * Processes a symbolic link.
 *
 * @param {string} entryPath - The path to the symbolic link.
 * @param {string} targetPath - The target path of the symbolic link.
 * @param {ProcessingStats} stats - The processing statistics.
 * @param {FileInfo[]} files - The array to store file information.
 * @param {ProcessingOptions} options - The processing options.
 * @returns {FileInfo[]} An array of file information from the target.
 */
const processSymlink = (entryPath, targetPath, stats, files, options) => {
  const symlinkKey = `${entryPath}:${targetPath}`;
  if (stats.seenSymlinks.has(symlinkKey)) {
    if (!options.ultraQuiet) {
      console.warn(
        `Circular symlink detected: ${entryPath} -> ${targetPath}`
      );
    }
    return [];
  }
  stats.seenSymlinks.add(symlinkKey);

  try {
    const targetStat = lstatSync(targetPath);
    if (targetStat.isDirectory()) {
      return processDirectory(targetPath, options, stats);
    } else {
      processFile(targetPath, options.maxFileSize, stats, files, options.rootPath, options);
      return [];
    }
  } catch (err) {
    if (!options.ultraQuiet) {
      console.warn(
        `Broken symlink or permission error: ${entryPath} -> ${targetPath}`
      );
    }
    return [];
  }
};

/**
 * Processes a single file.
 *
 * @param {string} filePath - The path to the file.
 * @param {number} maxFileSize - The maximum file size allowed.
 * @param {ProcessingStats} stats - The processing statistics.
 * @param {FileInfo[]} files - The array to store file information.
 * @param {string} rootPath - The absolute path of the root directory.
 * @param {ProcessingOptions} options - The processing options.
 */
const processFile = (filePath, maxFileSize, stats, files, rootPath, options) => {
  try {
    const fileSize = lstatSync(filePath).size;

    if (fileSize > maxFileSize) {
      stats.skippedFiles++;
      if (!options.quiet && !options.ultraQuiet) {
        console.warn(`${FORMAT.bold('Skipping file larger than maxFileSize:')} ${filePath}`);
      }
      return;
    }

    if (stats.totalSize + fileSize > options.maxTotalSize) {
      stats.sizeLimitReached = true;
      if (!options.quiet && !options.ultraQuiet) {
        console.warn(`${FORMAT.bold('Total size limit reached at:')} ${filePath}`);
      }
      return;
    }

    if (!isTextFile(filePath)) {
      stats.nonTextFiles++;
      if (!options.quiet && !options.ultraQuiet) {
        console.warn(`${FORMAT.bold('Skipping non-text file:')} ${filePath}`);
      }
      return;
    }

    stats.totalSize += fileSize;
    stats.fileCount++;

    const relativePath = relative(rootPath, filePath);
    files.push({
      path:    relativePath,
      content: readFileContent(filePath, maxFileSize),
      size:    fileSize,
    });

    // Log the file added to the digest
    if (!options.quiet && !options.ultraQuiet) {
      console.log(`${FORMAT.bold('Added to digest:')} ${relativePath}`);
    }

  } catch (error) {
    stats.addError(error);
    console.error(`Error processing file ${filePath}: ${error.message}`);
  }
};

/**
 * Processes a directory recursively.
 *
 * @param {string} dirPath - The path to the directory.
 * @param {ProcessingOptions} options - The processing options.
 * @param {ProcessingStats} stats - The processing statistics.
 * @returns {FileInfo[]} An array of file information.
 */
const processDirectory = (
  dirPath,
  {
    ignorePatterns,
    includePatterns = [],
    maxFileSize     = MAX_FILE_SIZE,
    maxTotalSize    = MAX_TOTAL_SIZE_BYTES,
    maxDepth        = MAX_DIRECTORY_DEPTH,
    currentDepth    = 0,
    rootPath        = dirPath,
    quiet,
    ultraQuiet,
    omitExcluded,
  },
  stats = createStats()
) => {
  /**
   * @type {FileInfo[]}
   */
  const files = [];

  if (currentDepth > maxDepth) {
    if (!ultraQuiet) {
      console.warn(`Max directory depth reached at ${dirPath}`);
    }
    return files;
  }

  const resolvedPath = resolve(dirPath);
  if (stats.seenPaths.has(resolvedPath)) {
    if (!ultraQuiet) {
      console.warn(`Circular reference detected at ${dirPath}, skipping.`);
    }
    return files;
  }
  stats.seenPaths.add(resolvedPath);

  try {
    const entries = readdirSync(dirPath, { withFileTypes: true });

    for (const entry of entries) {
      if (stats.sizeLimitReached) {
        break;
      }

      const entryPath         = join(dirPath, entry.name);
      const relativeEntryPath = relative(rootPath, entryPath);

      if (omitExcluded) {
        if (
          shouldIgnore(relativeEntryPath, ignorePatterns, {
            nocase: true,
            dot:    true,
          }, stats)
        ) {
          stats.excludedFiles++;
          continue;
        }
        if (
          includePatterns.length > 0 &&
          !includePatterns.some((p) =>
            miniMatch(
              normalize(relativeEntryPath).split(sep).join('/'),
              p,
              { nocase: true, dot: true, matchBase: !p.includes('/') }
            )
          )
        ) {
          stats.excludedFiles++;
          continue;
        }
      }

      if (entry.isSymbolicLink()) {
        try {
          const targetPath = resolve(
            dirname(entryPath),
            readlinkSync(entryPath)
          );
          const symlinks = processSymlink(
            entryPath,
            targetPath,
            stats,
            files,
            {
              ignorePatterns,
              includePatterns,
              maxFileSize,
              maxTotalSize,
              maxDepth,
              currentDepth: currentDepth + 1,
              rootPath,
              quiet,
              ultraQuiet,
              omitExcluded,
            }
          );
          files.push(...symlinks);
        } catch (error) {
          stats.addError(error);
          if (!ultraQuiet) {
            console.error(
              `Error processing symlink ${entryPath}: ${error.message}`
            );
          }
        }
      } else if (entry.isDirectory()) {
        const subFiles = processDirectory(
          entryPath,
          {
            ignorePatterns,
            includePatterns,
            maxFileSize,
            maxTotalSize,
            maxDepth,
            currentDepth: currentDepth + 1,
            rootPath,
            quiet,
            ultraQuiet,
            omitExcluded,
          },
          stats
        );
        files.push(...subFiles);
      } else if (entry.isFile()) {
        processFile(entryPath, maxFileSize, stats, files, rootPath, { quiet, ultraQuiet });
      }
    }
  } catch (error) {
    stats.addError(error);
    if (!ultraQuiet) {
      console.error(`Error reading directory ${dirPath}: ${error.message}`);
    }
  }

  return files;
};

/**
 * Generates a tree-like directory structure string.
 *
 * @param {string} dirPath - The path to the directory.
 * @param {string[]} ignorePatterns - The patterns to ignore.
 * @param {string[]} includePatterns - The patterns to include.
 * @param {number} maxDepth - The maximum depth to traverse.
 * @param {number} [currentDepth=0] - The current depth.
 * @param {string} [prefix=''] - The prefix for indentation.
 * @param {string} [rootPath=dirPath] - The root path.
 * @param {{content: string, truncated: boolean}} [result={ content: '', truncated: false }] - The result object.
 * @param {boolean} ultraQuiet - Whether to suppress all non-error output.
 * @param {boolean} omitExcluded - Whether to omit excluded files from the tree.
 * @returns {string} The directory tree string.
 */
const generateDirectoryTree = (
  dirPath,
  ignorePatterns,
  includePatterns,
  maxDepth,
  currentDepth = 0,
  prefix       = '',
  rootPath     = dirPath,
  result       = { content: '', truncated: false },
  ultraQuiet   = false,
  omitExcluded = false
) => {
  if (currentDepth > maxDepth || result.truncated) {
    return result.content;
  }

  try {
    const entries = readdirSync(dirPath, { withFileTypes: true });
    let filteredEntries = entries;

    if (omitExcluded) {
      filteredEntries = entries
        .filter((entry) => {
          const rel = normalize(relative(rootPath, join(dirPath, entry.name))).split(sep).join('/');
          return !shouldIgnore(rel, ignorePatterns, { nocase: true, dot: true })
            && (
              includePatterns.length === 0
              || includePatterns.some((p) =>
                  miniMatch(rel, p, {
                    nocase: true,
                    dot: true,
                    matchBase: !p.includes('/'),
                  })
                )
            );
        });
    }

    filteredEntries.forEach((entry, index) => {
      if (result.content.length > CHUNK_SIZE) {
        result.truncated = true;
        return;
      }

      const isLast    = index === filteredEntries.length - 1;
      const entryPath = join(dirPath, entry.name);

      result.content += `${prefix}${isLast ? '└── ' : '├── '}${entry.name}${
        entry.isDirectory() ? '/' : ''
      }\n`;

      if (entry.isDirectory() && !result.truncated) {
        generateDirectoryTree(
          entryPath,
          ignorePatterns,
          includePatterns,
          maxDepth,
          currentDepth + 1,
          `${prefix}${isLast ? '    ' : '│   '}`,
          rootPath,
          result,
          ultraQuiet,
          omitExcluded
        );
      }
    });
  } catch (error) {
    if (!ultraQuiet) {
      console.error(
        `Error generating directory tree for ${dirPath}: ${error.message}`
      );
    }
  }

  return result.truncated
    ? result.content + '\n[Directory tree truncated due to size]'
    : result.content;
};

/**
 * Validates the command line arguments.
 *
 * @param {Object} args - The parsed command line arguments.
 * @param {number} args.maxSize - The maximum file size.
 * @param {number} args.maxTotalSize - The maximum total size.
 * @param {number} args.maxDepth - The maximum directory depth.
 * @param {string|null} args.ignoreFile - Path to the ignore file.
 * @param {string|null} args.includeFile - Path to the include file.
 * @param {boolean} args.quiet - Whether quiet mode is enabled.
 * @param {boolean} args.ultraQuiet - Whether ultra-quiet mode is enabled.
 * @param {boolean} args.omitExcluded - Whether to omit excluded files from the tree.
 * @throws {Error} If any argument is invalid.
 */
const validateArgs = (args) => {
  const errors = [];

  if (args.maxSize      <= 0) errors.push('maxSize must be positive');
  if (args.maxTotalSize <= 0) errors.push('maxTotalSize must be positive');
  if (args.maxDepth     <= 0) errors.push('maxDepth must be positive');

  if (args.ignoreFile && !existsSync(args.ignoreFile)) {
    errors.push(`Ignore file not found: ${args.ignoreFile}`);
  }

  if (args.includeFile && !existsSync(args.includeFile)) {
    errors.push(`Include file not found: ${args.includeFile}`);
  }

  if (errors.length > 0) {
    throw new Error(`Invalid arguments:\n${errors.join('\n')}`);
  }
};

/**
 * Loads patterns from a file.
 *
 * @param {string} filePath - The path to the file.
 * @returns {string[]} An array of patterns.
 */
const loadPatternsFromFile = (filePath) => {
  try {
    if (!filePath) return [];
    const content = readFileSync(filePath, 'utf-8');
    return content
      .split('\n')
      .map((line) => line.trim())
      .filter((line) => line !== '' && !line.startsWith('#'));
  } catch (error) {
    console.error(`Error reading patterns from ${filePath}: ${error.message}`);
    return [];
  }
};

/**
 * Generates a summary of the processing results.
 *
 * @param {string} path - The path to the processed directory.
 * @param {ProcessingStats} stats - The processing statistics.
 * @param {ProcessingOptions} options - The processing options.
 * @param {string} outputFile - The path to the digest output file.
 * @returns {string} The summary string.
 */
const generateSummary = (path, stats, options, outputFile) => {
  const {
    includePatterns,
    maxFileSize,
    maxTotalSize,
    maxDepth,
    quiet,
    ultraQuiet,
    omitExcluded,
  } = options;

  const executionTime = Date.now() - stats.startTime;

  const {
    bold,
    red,
    green,
    yellow,
    white,
    gray,
    invert,
  } = FORMAT;

  return `
${invert(bold(' Digest Summary '))}
${white('Processed directory:')}         ${gray(path)}
${white('Execution time:')}              ${yellow((executionTime / 1000).toFixed(2))} ${gray('seconds')}
${white('Files added to digest:')}       ${green(stats.fileCount)}
${white('Files excluded by pattern:')}   ${red(stats.excludedFiles)}
${white('Files excluded (non-text):')}   ${red(stats.nonTextFiles)}
${white('Files skipped (size limit):')}  ${red(stats.skippedFiles)}
${white('Total size:')}                  ${yellow(formatBytes(stats.totalSize))}
${white('Size limit reached:')}          ${stats.sizeLimitReached ? red('Yes') : green('No')}

${invert(bold(' Configuration '))}
${white('Max file size:')}       ${yellow(formatBytes(maxFileSize))}
${white('Max total size:')}      ${yellow(formatBytes(maxTotalSize))}
${white('Max directory depth:')} ${yellow(maxDepth)}
${white('Omit excluded from tree:')} ${omitExcluded ? green('Yes') : red('No')}
${bold('Ignore patterns that matched:')} ${
    stats.matchedIgnorePatterns.size
      ? `\n  ${gray(Array.from(stats.matchedIgnorePatterns).join('\n  '))}`
      : 'None'
}
${white('Include patterns:')}   ${
    includePatterns.length ? `\n  ${gray(includePatterns.join('\n  '))}` : 'None'
}

${invert(bold(` Errors (${stats.errors.length}) `))}
${
    stats.errors.length
      ? stats.errors
          .map((err) => `${err.timestamp}: ${err.message}`)
          .join('\n')
      : 'No errors occurred'
}

${invert(bold(' Digest File '))}
${outputFile}
`;
};

/**
 * Parses command line arguments.
 *
 * @returns {Object} The parsed arguments.
 */
const parseArgs = () => {
  const args = process.argv.slice(2);
  const parsedArgs = {
    path:                '.',
    outputFile:          'digest.txt',
    ignoreFile:          null,
    includeFile:         null,
    ignorePatterns:      [],
    includePatterns:     [],
    maxSize:             MAX_FILE_SIZE,
    maxTotalSize:        MAX_TOTAL_SIZE_BYTES,
    maxDepth:            MAX_DIRECTORY_DEPTH,
    quiet:               false,
    ultraQuiet:          false,
    omitExcluded:        false,
    skipDefaultIgnore:   false,
  };

  for (let i = 0; i < args.length; i++) {
    switch (args[i]) {
      // Long options
      case '--path':                parsedArgs.path              = args[++i]; break;
      case '--output':              parsedArgs.outputFile        = args[++i]; break;
      case '--ignore':              parsedArgs.ignoreFile        = args[++i]; break;
      case '--include':             parsedArgs.includeFile       = args[++i]; break;
      case '--ignore-pattern':      parsedArgs.ignorePatterns.push(args[++i]); break;
      case '--include-pattern':     parsedArgs.includePatterns.push(args[++i]); break;
      case '--max-size':            parsedArgs.maxSize           = parseInt(args[++i], 10); break;
      case '--max-total-size':      parsedArgs.maxTotalSize      = parseInt(args[++i], 10); break;
      case '--max-depth':           parsedArgs.maxDepth          = parseInt(args[++i], 10); break;
      case '--omit-excluded':       parsedArgs.omitExcluded      = true; break;
      case '--quiet':               parsedArgs.quiet             = true; break;
      case '--ultra-quiet':         parsedArgs.ultraQuiet        = true; break;
      case '--skip-default-ignore': parsedArgs.skipDefaultIgnore = true; break;
      case '--help':                printHelp(); process.exit(0);

      // Short options
      case '-p':                    parsedArgs.path              = args[++i]; break;
      case '-o':                    parsedArgs.outputFile        = args[++i]; break;
      case '-g':                    parsedArgs.ignoreFile        = args[++i]; break;
      case '-n':                    parsedArgs.includeFile       = args[++i]; break;
      case '-i':                    parsedArgs.ignorePatterns.push(args[++i]); break;
      case '-I':                    parsedArgs.includePatterns.push(args[++i]); break;
      case '-s':                    parsedArgs.maxSize           = parseInt(args[++i], 10); break;
      case '-t':                    parsedArgs.maxTotalSize      = parseInt(args[++i], 10); break;
      case '-d':                    parsedArgs.maxDepth          = parseInt(args[++i], 10); break;
      case '-q':                    parsedArgs.quiet             = true; break;
      case '-uq':                   parsedArgs.ultraQuiet        = true; break;
      case '-k':                    parsedArgs.skipDefaultIgnore = true; break;
      case '-h':                    printHelp(); process.exit(0);
      default:
        console.warn(`Unknown option: ${args[i]}`);
        printHelp();
        process.exit(1);
    }
  }

  return parsedArgs;
};

/**
 * Prints the help message with usage examples.
 */
const printHelp = () => {
  console.log(`
Usage: node codedigest.mjs [options]

Options:
  --path <path>, -p <path>                 Directory to process (default: current directory)
  --output <file>, -o <file>               Output file path (default: digest.txt)
  --ignore <file>, -g <file>               File containing ignore patterns
  --include <file>, -n <file>              File containing include patterns
  --ignore-pattern <pattern>, -i <pattern> Ignore pattern (can be used multiple times)
  --include-pattern <pattern>, -I <pattern>Include pattern (can be used multiple times)
  --max-size <bytes>, -s <bytes>           Maximum file size (default: ${formatBytes(MAX_FILE_SIZE)})
  --max-total-size <bytes>, -t <bytes>     Maximum total size (default: ${formatBytes(MAX_TOTAL_SIZE_BYTES)})
  --max-depth <number>, -d <number>        Maximum directory depth (default: ${MAX_DIRECTORY_DEPTH})
  --omit-excluded                          Omit excluded files from the directory tree
  --quiet, -q                              Suppress 'Added' and 'Skipped' messages
  --ultra-quiet, -uq                       Suppress all non-error output
  --skip-default-ignore, -k                Skip default ignore patterns; use only user-provided patterns
  --help, -h                               Display this help message

Examples:
  # Basic usage with default options
  node codedigest.mjs

  # Specify a directory and output file
  node codedigest.mjs --path ./myproject --output mydigest.txt

  # Use ignore patterns from a file and add additional ignore patterns via command line
  node codedigest.mjs --ignore .gitignore --ignore-pattern '*.log' --ignore-pattern 'temp/'

  # Use include patterns to only include specific file types
  node codedigest.mjs --include '*.js' --include '*.md'

  # Combine include and ignore patterns
  node codedigest.mjs -p ./src -o digest.txt -g ignore.txt -i '*.test.js' -I '*.js'

  # Omit excluded files from the directory tree
  node codedigest.mjs --omit-excluded

  # Skip default ignore patterns and use only user-provided patterns
  node codedigest.mjs --skip-default-ignore --ignore-pattern 'custom/**/*.js'
`);
};

/**
 * Ensures that a directory exists, creating it if necessary.
 *
 * @param {string} dirPath - The path to the directory.
 */
const ensureDirectoryExists = (dirPath) => {
  if (!existsSync(dirPath)) {
    mkdirSync(dirPath, { recursive: true });
  }
};

/**
 * The main function of the script.
 */
const main = async () => {
  try {
    const args = parseArgs();
    validateArgs(args);

    // Bug fix: Instead of ignoring all user patterns, only skip the defaults if skipDefaultIgnore is set
    const ignorePatterns = [
      ...(args.skipDefaultIgnore ? [] : Array.from(DEFAULT_IGNORE_PATTERNS)),
      ...(args.ignoreFile ? loadPatternsFromFile(args.ignoreFile) : []),
      ...args.ignorePatterns,
    ];

    const includePatterns = [
      ...(args.includeFile ? loadPatternsFromFile(args.includeFile) : []),
      ...args.includePatterns,
    ];

    const rootPath       = resolve(args.path);
    const outputFilePath = resolve(args.outputFile);

    // Exclude the output file itself from the digest
    if (outputFilePath.startsWith(rootPath)) {
      const relativeOutputPath   = relative(rootPath, outputFilePath);
      const normalizedOutputPath = relativeOutputPath.split(sep).join('/');
      ignorePatterns.push(normalizedOutputPath);
    }

    if (!existsSync(args.path)) {
      throw new Error(`Path does not exist: ${args.path}`);
    }

    const stat = lstatSync(args.path);
    if (!stat.isDirectory()) {
      throw new Error(`Path is not a directory: ${args.path}`);
    }

    const options = {
      ignorePatterns,
      includePatterns,
      maxFileSize:  args.maxSize,
      maxTotalSize: args.maxTotalSize,
      maxDepth:     args.maxDepth,
      rootPath:     rootPath,
      quiet:        args.quiet,
      ultraQuiet:   args.ultraQuiet,
      omitExcluded: args.omitExcluded,
    };

    const statsObj = createStats();
    const files    = processDirectory(args.path, options, statsObj);

    const digestContent = files.map((file) => {
      const separator = '='.repeat(48) + '\n';
      return `${separator}File: ${file.path}\n${separator}${file.content}\n`;
    }).join('');

    const directoryTree = generateDirectoryTree(
      args.path,
      ignorePatterns,
      includePatterns,
      args.maxDepth,
      0,
      '',
      rootPath,
      { content: '', truncated: false },
      args.ultraQuiet,
      args.omitExcluded
    );

    const summary = generateSummary(args.path, statsObj, options, args.outputFile);

    ensureDirectoryExists(dirname(args.outputFile));
    writeFileSync(
      args.outputFile,
      `Directory Structure\n==================\n${directoryTree}\n\nFile Contents\n=============\n${digestContent}\n\n${summary}`
    );

    // Output the summary to the console
    if (!args.ultraQuiet) {
      console.log(summary);
    }

    if (statsObj.errors.length > 0 && !args.ultraQuiet) {
      console.warn(`\nWarning: ${statsObj.errors.length} errors occurred during processing. Check the console for details.`);
    }
  } catch (error) {
    console.error(`Fatal error: ${error.message}`);
    process.exit(1);
  }
};

main().catch((error) => {
  console.error('Unhandled error:', error);
  process.exit(1);
});

================================================
File: LICENSE
================================================
MIT License

Copyright (c) 2025 Phillip McNallen

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================================================
File: README.md
================================================
<p align="center">
  <img src="https://raw.githubusercontent.com/Nowayz/CodeDigest/refs/heads/resources/codedigest_logo.png" alt="logo"/>
</p>
**CodeDigest** is a single-file Node.js command-line tool that consolidates an entire code repository (directory structure and text-based files) into a digest file for easy consumption by your preferred LLM (Large Language Model). It helps you quickly gather all source code in one place so you can feed it into LLM-based tools for analysis, code generation, or any other AI-driven development workflows.

## Table of Contents

1. [Quick Start](#quick-start)
2. [Installation](#installation)
3. [Usage](#usage)
4. [Options](#options)
5. [Ignore & Include Patterns](#ignore--include-patterns)
6. [How It Works](#how-it-works)
7. [Nuances & Limits](#nuances--limits)
8. [License](#license)

### Quick Start

```bash
node ./codedigest.mjs --path ./myproject --output consolidated.txt
```

Once run, **`consolidated.txt`** will include:

1. A **directory tree** of `myproject` (excluding specified patterns).
2. **All text-based file contents** (subject to size limits).
3. A **summary** (stats, ignore patterns, errors, etc.).

#### Example Output
```
Directory Structure
===================
myproject/
├── package.json
├── index.js
├── src/
│   ├── app.js
│   └── utils.js
└── README.md

============================================
File: package.json
============================================
{
  "name": "myproject",
  "version": "1.0.0",
  ...
}

============================================
File: index.js
============================================
console.log("Hello World!");

etc...
```

This file can be fed directly to your LLM. For example, if you have an API or local setup where you can provide a text context to a language model, just drop the contents of `consolidated.txt` into the prompt or your specialized ingestion pipeline.

### Installation
1. Download `codedigest.mjs` and place it somewhere in your `PATH`.
2. Ensure you have [Node.js](https://nodejs.org) installed.
3. Run the script:
   ```bash
   node codedigest.mjs
   ```

### Usage
```bash
node codedigest.mjs --help
```
```
Usage: node codedigest.mjs [options]

Options:
  --path <path>, -p <path>             Directory to process (default: current directory)
  --output <file>, -o <file>           Output file path (default: digest.txt)
  --ignore <file>, -g <file>           File containing ignore patterns
  --include <file>, -n <file>          File containing include patterns
  --ignore-pattern <pattern>, -i <pattern>
                                       Ignore pattern (can be used multiple times)
  --include-pattern <pattern>, -I <pattern>
                                       Include pattern (can be used multiple times)
  --max-size <bytes>, -s <bytes>       Maximum file size (default: 10 MB)
  --max-total-size <bytes>, -t <bytes> Maximum total size (default: 500 MB)
  --max-depth <number>, -d <number>    Maximum directory depth (default: 20)
  --omit-excluded                      Omit excluded files from the directory tree
  --quiet, -q                          Suppress 'Added' and 'Skipped' messages
  --ultra-quiet, -uq                   Suppress all non-error output
  --help, -h                           Display this help message

Examples:
  # Basic usage with default options
  node codedigest.mjs 

  # Specify a directory and output file
  node codedigest.mjs --path ./myproject --output mydigest.txt

  # Use ignore patterns from a file and add additional ignore patterns via command line
  node codedigest.mjs --ignore .gitignore --ignore-pattern '*.log' --ignore-pattern 'temp/'

  # Use include patterns to only include specific file types
  node codedigest.mjs --include '*.js' --include '*.md'

  # Combine include and ignore patterns
  node codedigest.mjs -p ./src -o digest.txt -g ignore.txt -i '*.test.js' -I '*.js'

  # Omit excluded files from the directory tree
  node codedigest.mjs --omit-excluded
```

### Options

| Option                        | Alias | Description                                                | Default                 |
|-------------------------------|-------|------------------------------------------------------------|-------------------------|
| `--path <path>`               | `-p`  | Directory to process.                                     | `.` (current directory) |
| `--output <file>`             | `-o`  | Output file path.                                          | `digest.txt`           |
| `--ignore <file>`             | `-g`  | File containing ignore patterns.                           | —                       |
| `--include <file>`            | `-n`  | File containing include patterns.                          | —                      |
| `--ignore-pattern <pattern>`  | `-i`  | Add an ignore pattern (can be used multiple times).        | —                       |
| `--include-pattern <pattern>` | `-I`  | Add an include pattern (can be used multiple times).       | —                       |
| `--max-size <bytes>`          | `-s`  | Maximum individual file size (in bytes).                   | `10 MB`                |
| `--max-total-size <bytes>`    | `-t`  | Maximum total size (in bytes) before digest stops adding.  | `500 MB`               |
| `--max-depth <number>`        | `-d`  | Maximum directory depth.                                   | `20`                   |
| `--omit-excluded`             | —     | Omit excluded files from the directory tree to reduce clutter. | `false`            |
| `--quiet`                     | `-q`  | Suppress "Added" and "Skipped" messages.                   | `false`                |
| `--ultra-quiet`               | `-uq` | Suppress all non-error output.                             | `false`                |
| `--help`                      | `-h`  | Show help message.                                         | —                       |

### Ignore & Include Patterns

**CodeDigest** comes with a comprehensive set of default ignore patterns to exclude common files and directories that are typically unnecessary for analysis or could clutter the digest. Below is the **full list of default exclude patterns**:

**Note:** Always ensure that the default ignore patterns align with your project's specific needs. You can customize them further using the provided command-line options to tailor the digest to your requirements.

```plaintext
*.pyc
*.pyo
*.pyd
__pycache__
.pytest_cache
.coverage
.tox
.nox
.mypy_cache
.ruff_cache
.hypothesis
poetry.lock
Pipfile.lock
node_modules
bower_components
package-lock.json
yarn.lock
.npm
.yarn
.pnpm-store
*.class
*.jar
*.war
*.ear
*.nar
.gradle/
build/
.settings/
.classpath
gradle-app.setting
*.gradle
.project
*.o
*.obj
*.dll
*.dylib
*.exe
*.lib
*.out
*.a
*.pdb
.build/
*.xcodeproj/
*.xcworkspace/
*.pbxuser
*.mode1v3
*.mode2v3
*.perspectivev3
*.xcuserstate
xcuserdata/
.swiftpm/
*.gem
.bundle/
vendor/bundle
Gemfile.lock
.ruby-version
.ruby-gemset
.rvmrc
Cargo.lock
**/*.rs.bk
target/
pkg/
obj/
*.suo
*.user
*.userosscache
*.sln.docstates
packages/
*.nupkg
bin/
.git
.svn
.hg
.gitignore
.gitattributes
.gitmodules
*.svg
*.png
*.jpg
*.jpeg
*.gif
*.ico
*.pdf
*.mov
*.mp4
*.mp3
*.wav
venv
.venv
env
.env
virtualenv
.idea
.vscode
.vs
*.swo
*.swn
.settings
*.sublime-*
*.log
*.bak
*.swp
*.tmp
*.temp
.cache
.sass-cache
.eslintcache
.DS_Store
Thumbs.db
desktop.ini
build
dist
target
out
*.egg-info
*.egg
*.whl
*.so
site-packages
.docusaurus
.next
.nuxt
*.min.js
*.min.css
*.map
.terraform
*.tfstate*
vendor/
```

**Explanation of Common Patterns:**

- **Version Control Directories:** `.git`, `.svn`, `.hg` – These directories contain version control metadata and are typically not needed in a code digest.
- **Dependency Directories:** `node_modules`, `vendor/bundle`, `build`, `dist`, `target`, `pkg`, `bin`, etc. – These directories usually contain dependencies or build artifacts that can be large and are often unnecessary for code analysis.
- **Cache Directories and Files:** `__pycache__`, `.pytest_cache`, `.mypy_cache`, `.cache`, `.sass-cache`, etc. – These are used for caching compiled files or test results and are not relevant for code digestion.
- **Compiled and Binary Files:** `*.pyc`, `*.pyo`, `*.class`, `*.jar`, `*.dll`, `*.exe`, `*.so`, etc. – These are compiled or binary files that are not human-readable and generally not needed.
- **IDE and Editor Configurations:** `.idea`, `.vscode`, `.sublime-*`, `.project`, `.classpath`, etc. – These files are specific to development environments and editors.
- **Log and Temporary Files:** `*.log`, `*.tmp`, `*.temp`, `*.bak`, `*.swp`, etc. – These files are typically temporary or logs that are not useful for code analysis.
- **Media Files:** `*.svg`, `*.png`, `*.jpg`, `*.jpeg`, `*.gif`, `*.ico`, `*.pdf`, `*.mov`, `*.mp4`, `*.mp3`, `*.wav`, etc. – These files are non-textual and usually not necessary for code digestion.
- **Lock Files:** `poetry.lock`, `Pipfile.lock`, `package-lock.json`, `yarn.lock`, `Cargo.lock` – These files lock dependencies but may not be needed in the digest.
- **Others:** Patterns like `**/*.rs.bk`, `*.min.js`, `*.min.css`, etc., exclude backup files and minified code which can be less readable.

**Customizing Ignore Patterns:**

- **Via Command Line:**
  - Add extra patterns using `--ignore-pattern` or `-i`. For example:
    ```bash
    node codedigest.mjs --ignore-pattern '*.log' --ignore-pattern 'temp/'
    ```
- **Via Ignore File:**
  - Create a file (e.g., `.gitignore`) with your custom ignore patterns and specify it using `--ignore <file>` or `-g <file>`. For example:
    ```bash
    node codedigest.mjs --ignore .gitignore
    ```

### Include Patterns
- If **include** patterns are specified, **only** files matching those patterns are processed (unless ignored).
- Useful if you only want `.js`, `.py`, etc.

For example:
```bash
./codedigest.mjs --path ./myproject \
  --include-pattern '*.js' \
  --include-pattern '*.md'
```

### How CodeDigest Works

1. **Directory Traversal**  
   Recursively scans folders up to a user-defined depth, respecting symlinks (and avoiding loops).
2. **Ignore/Include Checking**  
   Skips any paths matching ignore patterns. Uses include patterns to filter if specified.
3. **File Reading**  
   - Only reads **text-based** files (checked by extension and simple binary detection).  
   - Skips files larger than `--max-size`.  
   - Stops adding new files once `--max-total-size` is reached (but still traverses the structure).
4. **Omitting Excluded Files from Directory Tree**  
   - When `--omit-excluded` is enabled, excluded files and directories are not displayed in the directory tree, reducing clutter especially in projects with large dependencies like `node_modules`.
5. **Single File Output**  
   - Generates a **directory tree** in text form (optionally omitting excluded files).  
   - Appends each included file's content to the digest.  
   - Summarizes stats (files processed, excluded, errors, etc.) at the end.

### Nuances & Limits

- **Size Limits**  
  - Default `--max-size=10MB`, `--max-total-size=500MB`.  
  - Prevents producing massive output files that are unwieldy or slow to load into an LLM.
- **Directory Depth**  
  - Default `--max-depth=20`.  
  - Prevents running forever on enormous or deeply nested repositories.
- **Symlinks**  
  - Symlinks are tracked so CodeDigest doesn’t loop infinitely on recursive links.
  - Broken symlinks generate warnings but do not stop the script.
- **File Type Detection**  
  - A set of known text extensions is used (e.g., `.js`, `.py`, `.md`, etc.).  
  - Otherwise checks for null characters.
- **Large Directories**  
  - For big projects, be mindful of memory and time. Possibly add more ignore patterns or reduce `--max-depth`.
- **Omitting Excluded Files**  
  - Using `--omit-excluded` helps in keeping the directory tree clean by excluding files and directories that match ignore patterns. This is particularly useful for projects with large dependency directories like `node_modules` or extensive import structures, ensuring the directory tree remains readable and focused on relevant parts of the codebase.

### License

This project is licensed under the [MIT License](LICENSE). You can use, modify, and distribute the code as long as the original license is included.

**Enjoy CodeDigest!**  
If you have questions or ideas, open an issue or PR.




[7m[1m Digest Summary [0m[27m
[37mProcessed directory:[0m         [90m.[0m
[37mExecution time:[0m              [33m0.04[0m [90mseconds[0m
[37mFiles added to digest:[0m       [32m30[0m
[37mFiles excluded by pattern:[0m   [31m0[0m
[37mFiles excluded (non-text):[0m   [31m7[0m
[37mFiles skipped (size limit):[0m  [31m0[0m
[37mTotal size:[0m                  [33m73.87 KB[0m
[37mSize limit reached:[0m          [32mNo[0m

[7m[1m Configuration [0m[27m
[37mMax file size:[0m       [33m10 MB[0m
[37mMax total size:[0m      [33m500 MB[0m
[37mMax directory depth:[0m [33m20[0m
[37mOmit excluded from tree:[0m [31mNo[0m
[1mIgnore patterns that matched:[0m None
[37mInclude patterns:[0m   None

[7m[1m Errors (0) [0m[27m
No errors occurred

[7m[1m Digest File [0m[27m
digest.txt
